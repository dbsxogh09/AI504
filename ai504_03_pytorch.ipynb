{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbsxogh09/AI504/blob/main/ai504_03_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbjN-8O3sp9I"
      },
      "source": [
        "# Week 3: PyTorch, Logistic Regression and MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd7_qFa6sp9I"
      },
      "source": [
        "- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n",
        "- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n",
        "- We will use simple linear model and multi-layer perceptron (MLP) in this class\n",
        "\n",
        "If you have any questions, feel free to ask\n",
        "- For additional questions, post questions in classum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_6tgh_lsp9I"
      },
      "source": [
        "## Why PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMwIjuVvsp9J"
      },
      "source": [
        "- Intuitive and concise code\n",
        "- Define by Run method (Tensorflow is Define and Run method)\n",
        "- High compatibility with Numpy (almost one-to-one mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O3b-lLfsp9J"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AofEmIygsp9J"
      },
      "source": [
        "## 0. Prelim: Load packages & GPU setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fia9Dz_Osp9J",
        "outputId": "ab865a75-5a83-44a8-ba54-20f25e2744cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct  5 13:10:25 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# visualize current GPU usages in your server\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpustat\n",
        "!gpustat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgee4YAM9pCu",
        "outputId": "e5007486-d384-4109-9414-78465af9a49c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpustat\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nvidia-ml-py>=11.450.129 (from gpustat)\n",
            "  Downloading nvidia_ml_py-12.535.108-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from gpustat) (5.9.5)\n",
            "Collecting blessed>=1.17.1 (from gpustat)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat) (0.2.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat) (1.16.0)\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1.1-py3-none-any.whl size=26534 sha256=468267f58618de5da930a6d195640b781d241050ff4d8b20ffd3f2056aaeebed\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/d7/80/a71ba3540900e1f276bcae685efd8e590c810d2108b95f1e47\n",
            "Successfully built gpustat\n",
            "Installing collected packages: nvidia-ml-py, blessed, gpustat\n",
            "Successfully installed blessed-1.20.0 gpustat-1.1.1 nvidia-ml-py-12.535.108\n",
            "\u001b[1m\u001b[37mfb6e68d5daf6\u001b[m  Thu Oct  5 13:11:27 2023  \u001b[1m\u001b[30m525.105.17\u001b[m\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla T4\u001b[m |\u001b[1m\u001b[31m 57°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m15360\u001b[m MB |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pTj8gTCqsp9K"
      },
      "outputs": [],
      "source": [
        "# set gpu by number\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXLR6ixYsp9L",
        "outputId": "57e3ea2d-7188-44d6-873f-b644af9b3d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# load packages\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk1UF7XYsp9L",
        "outputId": "962c7ad6-d289-42c4-8b37-4f66339a3d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "# print the version of PyTorch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vUJG0Ofsp9L"
      },
      "source": [
        "## 1. PyTorch Tensors and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG5rTO8tsp9L"
      },
      "source": [
        "PyTorch use **tensor**: the basic data structure in PyTorch.\\\n",
        "**Tensor: n-dimensional array + GPU calculation is supported**\\\n",
        "**Almost the same with Numpy array**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0luwTVGsp9L"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPaY0_2bsp9M"
      },
      "source": [
        "### PyTorch Tensors and Numpy shares almost identical grammer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ye-IRxsp9M"
      },
      "source": [
        "\n",
        "**We will show some examples of:**\n",
        "- Same operation with identical grammer\n",
        "- Same operation with different grammer\n",
        "- Different operation with same grammer\n",
        "\n",
        "**We will not handle all examples in this class :(**\n",
        "- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5RrHkDdsp9O"
      },
      "source": [
        "**First! Define Numpy array and PyTorch tensor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT6LsNonsp9O",
        "outputId": "dd336f67-3818-45ca-b41c-433274139103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4]\n",
            "[5 6 7 8]\n",
            "tensor([1, 2, 3, 4])\n",
            "tensor([5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "np_array_1 = np.array([1, 2, 3, 4])\n",
        "np_array_2 = np.array([5, 6, 7, 8])\n",
        "torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n",
        "torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n",
        "\n",
        "print (np_array_1)\n",
        "print (np_array_2)\n",
        "print (torch_tensor_1)\n",
        "print (torch_tensor_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyb-3ySEsp9O"
      },
      "source": [
        "**1) Same operations with identical grammer**\n",
        "\n",
        "Example) Get the shape of the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVKGdRwNsp9P",
        "outputId": "dc7296f0-82be-4581-a684-ea5dfd8df6b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4,)\n",
            "torch.Size([4])\n",
            "torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "print (np_array_1.shape)\n",
        "\n",
        "# torch\n",
        "print (torch_tensor_1.shape)\n",
        "print (torch_tensor_1.size()) # size() and shape operation is identical in torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ph6yZ4Nsp9P"
      },
      "source": [
        "**2) Same operations with different grammer**\n",
        "\n",
        "Example 1) Concatenate two tensors\n",
        "- numpy use `np.concatenate`\n",
        "- torch use `torch.cat`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6AZYswBsp9P",
        "outputId": "04049109-a1bf-4c65-ddbc-7c00b4968bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----numpy----\n",
            "[1 2 3 4 5 6 7 8]\n",
            "----torch----\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_concate = np.concatenate([np_array_1, np_array_2], axis=0)\n",
        "print ('----numpy----')\n",
        "print (np_concate)\n",
        "\n",
        "# torch\n",
        "torch_concate= torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n",
        "print ('----torch----')\n",
        "print (torch_concate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_baPgLasp9Q"
      },
      "source": [
        "Example 2) reshape the tensor shape\n",
        "- numpy use `X.reshape`\n",
        "- torch use `X.view`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBMJhl6tsp9Q",
        "outputId": "184f5228-f8c6-4509-974c-0d9e7e487886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----numpy----\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [7 8]]\n",
            "(4, 2)\n",
            "----torch----\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n",
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_reshaped = np_concate.reshape(4, 2)\n",
        "print ('----numpy----')\n",
        "print (np_reshaped)\n",
        "print (np_reshaped.shape)\n",
        "\n",
        "# torch\n",
        "torch_reshaped = torch_concate.view(4, 2)\n",
        "print ('----torch----')\n",
        "print (torch_reshaped)\n",
        "print (torch_reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nQopYNcsp9Q"
      },
      "source": [
        "**3) Different operations with same grammer (Confusing operations)**\n",
        "\n",
        "Example) manipulation tensors\n",
        "- Same grammer `repeat`  has different operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL05Z6GYsp9R",
        "outputId": "49a013e9-10ad-44e0-99be-78805c4cb422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[1 2 3]\n",
            "[1 1 2 2 3 3]\n",
            "----torch----\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3, 1, 2, 3])\n",
            "----obtain the same result-----\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "tensor([[1, 1],\n",
            "        [2, 2],\n",
            "        [3, 3]])\n",
            "tensor([1, 1, 2, 2, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3])\n",
        "x_repeat = x.repeat(2)\n",
        "\n",
        "print ('----numpy----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(2)\n",
        "\n",
        "print ('----torch----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n",
        "print('----obtain the same result-----')\n",
        "x_repeat = x.view(3, 1)\n",
        "print (x_repeat)\n",
        "\n",
        "x_repeat = x_repeat.repeat(1, 2)\n",
        "print (x_repeat)\n",
        "\n",
        "x_repeat = x_repeat.view(-1)\n",
        "print (x_repeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQP6FnKbsp9R",
        "outputId": "3e9a4137-6ef2-4468-ca7d-1782de917f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# similar manipulation operation: stack & repeat\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(4)\n",
        "x_stack = torch.stack([x, x, x, x])\n",
        "\n",
        "print (x_repeat)\n",
        "print (x_stack)\n",
        "print (x_repeat.view(4, 3)) # reshape x\n",
        "print(x_repeat.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5eWKE4Nsp9R"
      },
      "source": [
        "## 2. Tensor operations under GPU utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXgOePsysp9R"
      },
      "source": [
        "Deep learning frameworks utilize GPUs to accelarate computations.\n",
        "\n",
        "In this section, we will learn **how to utilize GPU** in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEnKzXeIsp9S",
        "outputId": "1d3f12f5-4770-4a58-bf0a-d7ba0a30d3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())  # Is GPU accessible?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v4QF2qY3sp9S"
      },
      "outputs": [],
      "source": [
        "a = torch.ones(3)\n",
        "b = torch.randn(100, 50, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVxUVMzWsp9S",
        "outputId": "b58edb57-0c00-4204-e15e-5730723f27e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Sa9qkmausp9S"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ2pfjr6sp9T",
        "outputId": "9bec9954-d414-4290-cb84-3ced99cb6a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YBmLLHZ5sp9U"
      },
      "outputs": [],
      "source": [
        "# upload a and b to GPU\n",
        "a = a.to('cuda')\n",
        "b = b.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynnrZrqTsp9U",
        "outputId": "fc500dd6-b192-4526-e68b-8e8e329eebe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VhoePABXsp9U"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLvhKI2Dsp9U",
        "outputId": "8d3c0d19-3be5-4e50-d723-9c36e4aecf8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7cu4nPxrsp9V"
      },
      "outputs": [],
      "source": [
        "c = c.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9zTgtkjsp9V",
        "outputId": "22141cf0-005d-42a7-94c9-fa52fd97f4f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd96DeWesp9V"
      },
      "source": [
        "## 3. Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffTzyxGJsp9W"
      },
      "source": [
        "Central to all neural networks in PyTorch is the `autograd` package.\n",
        "\n",
        "The `autograd` package provides automatic differentiation for all operations on Tensors.\n",
        "\n",
        "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQFoPjiqsp9W"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXurRLYvsp9W",
        "outputId": "231ca69b-37f4-40be-b111-31fca685902b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPVaCg9Csp9W",
        "outputId": "3701ca12-b845-43f0-aa79-3d99120c03c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG5bWmCXsp9W",
        "outputId": "276f1df6-efee-4066-a34b-3128f611977e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KeFRqU-sp9X",
        "outputId": "e23dd685-e326-4290-dabe-c518587815ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = z.mean()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "vkGgBWjtsp9X"
      },
      "outputs": [],
      "source": [
        "y.retain_grad()\n",
        "z.retain_grad()\n",
        "out.backward()\n",
        "# do backward path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRbw5HOsp9X"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1JyMWTbaU6ktJAHx2XqiU7s4tId-cxiLF)\n",
        "![picture](https://drive.google.com/uc?id=17j-aNqj1yjZfVPCKZJRt6YVZ-7usf5PH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzKtqRSIsp9X",
        "outputId": "7993e2a9-f087-43d2-a8ab-3339b6bb1efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "print(z.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM28F_Ousp9Y"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1jPfdq6piSkkwZ21nX7kIBa-xGJE6uPBu)\n",
        "![picture](https://drive.google.com/uc?id=1NN0kpdvRRP9NwguXJHnU3u8VikMFUKw2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dts8XdHfsp9Y",
        "outputId": "2fa9d3cd-81fc-4fc7-fa9f-0c715b05e7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kBM2Emesp9Y"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1HllHu2CxuNFX8mc6QdQEEtnXJ3Rvo6TE)\n",
        "![picture](https://drive.google.com/uc?id=1jWJPOXVLG6mdUyDSklocNWPVa9Rg62K3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PN7HmPysp9Y",
        "outputId": "dc9c0fc3-0c49-4663-cda7-b9011b92e99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTnY5Phpsp9Y"
      },
      "source": [
        "### Efficient inference (testing) with torch.no_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kj0c60Hsp9Y"
      },
      "source": [
        "To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n",
        "\n",
        "Situation: when **gradient calculation is not required** e.g., inference\\\n",
        "Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NqOULboAsp9Y"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    x = torch.ones(2, 2, requires_grad=True)\n",
        "    y = x + 2\n",
        "    z = y * y * 3\n",
        "    out = z.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxw9FVOBsp9Z",
        "outputId": "9963f622-6fda-4f4e-9eef-2a27dfee845f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "aTeg9iG_sp9Z",
        "outputId": "e8afc09b-3e07-4267-b6dc-31c2b7eab3d6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-bf3332dd1f01>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## ERROR!!!!: we used torch.no_grad()!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "out.backward() ## ERROR!!!!: we used torch.no_grad()!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nje-BGjesp9Z"
      },
      "source": [
        "## 4. nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiVnymh6sp9Z"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXR5jfpqsp9Z"
      },
      "source": [
        "### Using pre-defined modules (subset of models) in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypn-7P5usp9a",
        "outputId": "e95f08e5-fe80-4b74-ed85-bef397197ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "\n",
        "print (X)\n",
        "print (X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_ad-ZLk5sp9a"
      },
      "outputs": [],
      "source": [
        "# input dim 3, output dim 1\n",
        "linear_fn = nn.Linear(3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIAeq3f-sp9a",
        "outputId": "7a6f7628-dc93-4946-cf4e-f13c257758dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=3, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "linear_fn  # WX + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smbL2japsp9a",
        "outputId": "619d49d4-068b-428b-9132-1e0a6004e8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6415],\n",
            "        [-0.0831]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ],
      "source": [
        "Y = linear_fn(X)\n",
        "print(Y)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSlHALX1sp9b",
        "outputId": "c0cd4193-87f5-4841-d265-83f3ece899a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-2.3458, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "Y = Y.sum()\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvztL-YIsp9b"
      },
      "source": [
        "You can use other types of `nn.Module` in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6AJekGzfsp9b"
      },
      "outputs": [],
      "source": [
        "nn.Conv2d\n",
        "nn.RNNCell\n",
        "nn.LSTMCell\n",
        "nn.GRUCell\n",
        "nn.Transformer;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlf9096Hsp9b"
      },
      "source": [
        "### How can we design a customized model (neural network)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "UJgtdOYrsp9c"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x) # Activation function\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr-1kleXsp9c"
      },
      "source": [
        "**What is activation function?**\n",
        "- They make non-linearity for deep neural networks\n",
        "- Therefore, deep neural networks can approximate complex functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "W_wSvJWmsp9c"
      },
      "outputs": [],
      "source": [
        "nn.Sigmoid\n",
        "nn.ReLU\n",
        "nn.LeakyReLU\n",
        "nn.Tanh;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smL1Be1Zsp9d"
      },
      "source": [
        "## 5. MNIST classification with PyTorch (Logistic regression & MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvSHOjDTsp9e"
      },
      "source": [
        "### What is MNIST & How to do multi-class classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy9gJi_hsp9e"
      },
      "source": [
        "The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "\n",
        "Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n",
        "\n",
        "Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq29uTPusp9e"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr5dJKxOsp9e"
      },
      "source": [
        "### Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "AEssd29Vsp9e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tcrRyzSsp9f"
      },
      "source": [
        "### Load datasets for training & testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZmTjH_3sp9f",
        "outputId": "c22c1905-19ad-4585-a811-f485c5d47345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 122209256.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 114171247.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 52865299.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21143761.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Usually we split the data into test & test, but MNIST provides splited data\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "# mini batch size\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCGo8Y1Tsp9f"
      },
      "source": [
        "### Define model (we will use one layer classifier first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GIxpsDbZsp9g"
      },
      "outputs": [],
      "source": [
        "# Define model class\n",
        "# This model has one hidden layer\n",
        "class Multinomial_logistic_regression(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Multinomial_logistic_regression, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "aAJBK_1ksp9g"
      },
      "outputs": [],
      "source": [
        "# Generate model\n",
        "model = Multinomial_logistic_regression(784, 10)  # init(784, 10)\n",
        "# input dim: 784  / output dim: 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eCAztzrsp9g",
        "outputId": "74b5ec3c-88de-4f2c-a981-dc7da41ff8fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Multinomial_logistic_regression(\n",
              "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "gfQW99qHsp9h"
      },
      "outputs": [],
      "source": [
        "# Upload model to GPU\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDf5serrsp9h"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4vBdxgxsp9h"
      },
      "source": [
        "Optimization is about finding the best solution (model parameter) that fits the given dataset!\n",
        "\n",
        "PyTorch optimizer is about **which optimization methods to use for training**\n",
        "\n",
        "We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "EOKbqVsOsp9h"
      },
      "outputs": [],
      "source": [
        "# Optimizer define\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1HbOMusp9h"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-DG5f50sp9i"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjwUv6E_sp9i",
        "outputId": "6c95bd4a-3297-4c44-9755-4850afd08f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.3389\n",
            "Epoch [1/10], Step [200/469], Loss: 0.2541\n",
            "Epoch [1/10], Step [300/469], Loss: 0.2933\n",
            "Epoch [1/10], Step [400/469], Loss: 0.3973\n",
            "Epoch [2/10], Step [100/469], Loss: 0.3464\n",
            "Epoch [2/10], Step [200/469], Loss: 0.3730\n",
            "Epoch [2/10], Step [300/469], Loss: 0.3668\n",
            "Epoch [2/10], Step [400/469], Loss: 0.3443\n",
            "Epoch [3/10], Step [100/469], Loss: 0.4333\n",
            "Epoch [3/10], Step [200/469], Loss: 0.1800\n",
            "Epoch [3/10], Step [300/469], Loss: 0.2343\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2547\n",
            "Epoch [4/10], Step [100/469], Loss: 0.2499\n",
            "Epoch [4/10], Step [200/469], Loss: 0.2613\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2172\n",
            "Epoch [4/10], Step [400/469], Loss: 0.3166\n",
            "Epoch [5/10], Step [100/469], Loss: 0.1807\n",
            "Epoch [5/10], Step [200/469], Loss: 0.2085\n",
            "Epoch [5/10], Step [300/469], Loss: 0.2614\n",
            "Epoch [5/10], Step [400/469], Loss: 0.4689\n",
            "Epoch [6/10], Step [100/469], Loss: 0.2504\n",
            "Epoch [6/10], Step [200/469], Loss: 0.1757\n",
            "Epoch [6/10], Step [300/469], Loss: 0.3342\n",
            "Epoch [6/10], Step [400/469], Loss: 0.2877\n",
            "Epoch [7/10], Step [100/469], Loss: 0.3247\n",
            "Epoch [7/10], Step [200/469], Loss: 0.2041\n",
            "Epoch [7/10], Step [300/469], Loss: 0.2601\n",
            "Epoch [7/10], Step [400/469], Loss: 0.2134\n",
            "Epoch [8/10], Step [100/469], Loss: 0.3100\n",
            "Epoch [8/10], Step [200/469], Loss: 0.2665\n",
            "Epoch [8/10], Step [300/469], Loss: 0.2466\n",
            "Epoch [8/10], Step [400/469], Loss: 0.3116\n",
            "Epoch [9/10], Step [100/469], Loss: 0.1495\n",
            "Epoch [9/10], Step [200/469], Loss: 0.2369\n",
            "Epoch [9/10], Step [300/469], Loss: 0.2514\n",
            "Epoch [9/10], Step [400/469], Loss: 0.2180\n",
            "Epoch [10/10], Step [100/469], Loss: 0.1857\n",
            "Epoch [10/10], Step [200/469], Loss: 0.4049\n",
            "Epoch [10/10], Step [300/469], Loss: 0.3771\n",
            "Epoch [10/10], Step [400/469], Loss: 0.2433\n"
          ]
        }
      ],
      "source": [
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (cross entropy loss) with ground truth & prediction value\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad() # To prevent gradients' accumulation\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRWIix5Ysp9i"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5MLTXr6sp9j",
        "outputId": "4be1c7d4-d6cc-4b40-8114-40e17a1ed595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 92.36 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  #because it is softmax value, classification -> get the label prediction of top 1\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u3eWP6Ysp9j"
      },
      "source": [
        "### New model: MLP (multi-layer-perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iubO05oLsp9j"
      },
      "source": [
        "Previous model used multinomial logistic regression (one linear layer)\\\n",
        "What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "P8HMCVbtsp9j"
      },
      "outputs": [],
      "source": [
        "# New model with multi layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        #self.fc4 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()  # sigmoid activation function (you can customize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc3(out)\n",
        "        #out = self.sigmoid(out)\n",
        "        #out = self.fc4(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnhBSqrgsp9k",
        "outputId": "4ce1db27-563f-43f1-b577-41eea690d796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 2.2830\n",
            "Epoch [1/10], Step [200/469], Loss: 2.0924\n",
            "Epoch [1/10], Step [300/469], Loss: 1.6016\n",
            "Epoch [1/10], Step [400/469], Loss: 1.3453\n",
            "Epoch [2/10], Step [100/469], Loss: 1.0782\n",
            "Epoch [2/10], Step [200/469], Loss: 0.9323\n",
            "Epoch [2/10], Step [300/469], Loss: 0.7414\n",
            "Epoch [2/10], Step [400/469], Loss: 0.6095\n",
            "Epoch [3/10], Step [100/469], Loss: 0.5381\n",
            "Epoch [3/10], Step [200/469], Loss: 0.5030\n",
            "Epoch [3/10], Step [300/469], Loss: 0.3988\n",
            "Epoch [3/10], Step [400/469], Loss: 0.4370\n",
            "Epoch [4/10], Step [100/469], Loss: 0.4054\n",
            "Epoch [4/10], Step [200/469], Loss: 0.4277\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2873\n",
            "Epoch [4/10], Step [400/469], Loss: 0.4587\n",
            "Epoch [5/10], Step [100/469], Loss: 0.3111\n",
            "Epoch [5/10], Step [200/469], Loss: 0.3448\n",
            "Epoch [5/10], Step [300/469], Loss: 0.2499\n",
            "Epoch [5/10], Step [400/469], Loss: 0.3648\n",
            "Epoch [6/10], Step [100/469], Loss: 0.3423\n",
            "Epoch [6/10], Step [200/469], Loss: 0.1940\n",
            "Epoch [6/10], Step [300/469], Loss: 0.2347\n",
            "Epoch [6/10], Step [400/469], Loss: 0.3879\n",
            "Epoch [7/10], Step [100/469], Loss: 0.3065\n",
            "Epoch [7/10], Step [200/469], Loss: 0.2864\n",
            "Epoch [7/10], Step [300/469], Loss: 0.3297\n",
            "Epoch [7/10], Step [400/469], Loss: 0.3233\n",
            "Epoch [8/10], Step [100/469], Loss: 0.2674\n",
            "Epoch [8/10], Step [200/469], Loss: 0.4298\n",
            "Epoch [8/10], Step [300/469], Loss: 0.3038\n",
            "Epoch [8/10], Step [400/469], Loss: 0.2793\n",
            "Epoch [9/10], Step [100/469], Loss: 0.2335\n",
            "Epoch [9/10], Step [200/469], Loss: 0.3517\n",
            "Epoch [9/10], Step [300/469], Loss: 0.2142\n",
            "Epoch [9/10], Step [400/469], Loss: 0.2309\n",
            "Epoch [10/10], Step [100/469], Loss: 0.2381\n",
            "Epoch [10/10], Step [200/469], Loss: 0.2992\n",
            "Epoch [10/10], Step [300/469], Loss: 0.3301\n",
            "Epoch [10/10], Step [400/469], Loss: 0.3309\n"
          ]
        }
      ],
      "source": [
        "# Generate model\n",
        "model = NeuralNet(784, 15, 10)  # init(784, 20, 10)\n",
        "# input dim: 784  / hidden dim: 20  / output dim: 10\n",
        "\n",
        "# Upload model to GPU\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.07, momentum=0.8)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (cross entropy loss) with ground truth & prediction value\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqzS5I06sp9k",
        "outputId": "950148df-36ae-4814-e0db-0e66e67f4222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 93.01 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classification -> get the label prediction of top 1\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jAvwUq1sp9l"
      },
      "source": [
        "### Change the following options to obtain better accuracy!! (try it by your-self)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWjgPRMzsp9l"
      },
      "source": [
        "#### (1) Model configurations:\n",
        "- size of hidden layer units\n",
        "- number of layers\n",
        "- type of activation function (e.g., relu, tanh, softplus etc.)\n",
        "\n",
        "#### (2) Optimization configurations\n",
        "- learning rate\n",
        "- epoch\n",
        "- type of optimizer\n",
        "- momentem hyperparameter"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}